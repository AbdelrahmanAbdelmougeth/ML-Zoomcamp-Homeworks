{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.10 Homework\n",
    "\n",
    "The goal of this homework is to create a tree-based regression model for prediction apartment prices (column `'price'`).\n",
    "\n",
    "In this homework we'll again use the New York City Airbnb Open Data dataset - the same one we used in homework 2 and 3.\n",
    "\n",
    "You can take it from [Kaggle](https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data?select=AB_NYC_2019.csv)\n",
    "or download from [here](https://raw.githubusercontent.com/alexeygrigorev/datasets/master/AB_NYC_2019.csv)\n",
    "if you don't want to sign up to Kaggle.\n",
    "\n",
    "Let's load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'neighbourhood_group', 'room_type', 'latitude', 'longitude',\n",
    "    'minimum_nights', 'number_of_reviews','reviews_per_month',\n",
    "    'calculated_host_listings_count', 'availability_365',\n",
    "    'price'\n",
    "]\n",
    "\n",
    "df = pd.read_csv('AB_NYC_2019.csv', usecols=columns)\n",
    "df.reviews_per_month = df.reviews_per_month.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Apply the log tranform to `price`\n",
    "* Do train/validation/test split with 60%/20%/20% distribution. \n",
    "* Use the `train_test_split` function and set the `random_state` parameter to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        5.010635\n",
       "1        5.420535\n",
       "2        5.017280\n",
       "3        4.499810\n",
       "4        4.394449\n",
       "           ...   \n",
       "48890    4.262680\n",
       "48891    3.713572\n",
       "48892    4.753590\n",
       "48893    4.025352\n",
       "48894    4.510860\n",
       "Name: price, Length: 48895, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_logs = np.log1p(df.price)\n",
    "df['price'] = price_logs\n",
    "df.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=11)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "y_train = df_train.price\n",
    "y_val = df_val.price\n",
    "y_test = df_test.price\n",
    "\n",
    "del df_train['price']\n",
    "del df_val['price']\n",
    "del df_test['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use `DictVectorizer` to turn train and validation into matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import export_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "train_dicts = df_train.fillna(0).to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "val_dicts = df_val.fillna(0).to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Let's train a decision tree regressor to predict the price variable. \n",
    "\n",
    "* Train a model with `max_depth=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=1)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor(max_depth=1)\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- room_type=Entire home/apt <= 0.50\n",
      "|   |--- value: [4.29]\n",
      "|--- room_type=Entire home/apt >  0.50\n",
      "|   |--- value: [5.16]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(export_text(dt, feature_names=dv.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which feature is used for splitting the data?\n",
    "\n",
    "* `room_type`\n",
    "* `neighbourhood_group`\n",
    "* `number_of_reviews`\n",
    "* `reviews_per_month`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Train a random forest model with these parameters:\n",
    "\n",
    "* `n_estimators=10`\n",
    "* `random_state=1`\n",
    "* `n_jobs=-1`  (optional - to make training faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y , y_pred):\n",
    "    se = (y - y_pred) ** 2\n",
    "    mse = se.mean()\n",
    "    return np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestRegressor(n_estimators=10,random_state=1,n_jobs=-1)\n",
    "clf.fit(X_train , y_train)\n",
    "y_pred = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.466"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(y_val , y_pred).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the RMSE of this model on validation?\n",
    "\n",
    "* 0.059\n",
    "* 0.259\n",
    "* 0.459\n",
    "* 0.659"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nearest one is 0.459"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Now let's experiment with the `n_estimators` parameter\n",
    "\n",
    "* Try different values of this parameter from 10 to 200 with step 10\n",
    "* Set `random_state` to `1`\n",
    "* Evaluate the model on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10.,  20.,  30.,  40.,  50.,  60.,  70.,  80.,  90., 100., 110.,\n",
       "       120., 130., 140., 150., 160., 170., 180., 190., 200.])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_e = np.linspace(start = 10,stop = 200, num = 20)\n",
    "n_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   10   0.4655\n",
      "   20   0.4526\n",
      "   30   0.4502\n",
      "   40   0.4493\n",
      "   50   0.4476\n",
      "   60   0.4466\n",
      "   70   0.4462\n",
      "   80   0.4461\n",
      "   90   0.4455\n",
      "  100   0.4453\n",
      "  110   0.4451\n",
      "  120   0.4448\n",
      "  130   0.4448\n",
      "  140   0.4445\n",
      "  150   0.4442\n",
      "  160   0.4442\n",
      "  170   0.4442\n",
      "  180   0.4442\n",
      "  190   0.4442\n",
      "  200   0.4442\n"
     ]
    }
   ],
   "source": [
    "for i in n_e:\n",
    "    f = i.astype(int)\n",
    "    clf = RandomForestRegressor(n_estimators=f,random_state=1,n_jobs=-1)\n",
    "    clf.fit(X_train , y_train)\n",
    "    y_pred = clf.predict(X_val)\n",
    "    rmse_ = rmse(y_val , y_pred).round(4)\n",
    "    print('%5s   %5s' % (f , rmse_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After which value of `n_estimators` does RMSE stop improving?\n",
    "\n",
    "- 10\n",
    "- 50\n",
    "- 70\n",
    "- 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE stops improving after 120 there is an improvment but we can neglect it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Let's select the best `max_depth`:\n",
    "\n",
    "* Try different values of `max_depth`: `[10, 15, 20, 25]`\n",
    "* For each of these values, try different values of `n_estimators` from 10 till 200 (with step 10)\n",
    "* Fix the random seed: `random_state=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "   10   0.4492\n",
      "   20   0.4459\n",
      "   30   0.4451\n",
      "   40   0.4449\n",
      "   50   0.4445\n",
      "   60   0.4442\n",
      "   70   0.4442\n",
      "   80   0.4442\n",
      "   90   0.4442\n",
      "  100   0.4443\n",
      "  110   0.4443\n",
      "  120   0.4442\n",
      "  130   0.4442\n",
      "  140   0.4441\n",
      "  150   0.4438\n",
      "  160   0.4438\n",
      "  170   0.4437\n",
      "  180   0.4437\n",
      "  190   0.4438\n",
      "  200   0.4438\n",
      "15\n",
      "   10   0.455\n",
      "   20   0.4469\n",
      "   30   0.4452\n",
      "   40   0.4441\n",
      "   50   0.4435\n",
      "   60   0.4425\n",
      "   70   0.4422\n",
      "   80   0.4418\n",
      "   90   0.4415\n",
      "  100   0.4415\n",
      "  110   0.4414\n",
      "  120   0.4412\n",
      "  130   0.4411\n",
      "  140   0.4409\n",
      "  150   0.4406\n",
      "  160   0.4406\n",
      "  170   0.4405\n",
      "  180   0.4405\n",
      "  190   0.4405\n",
      "  200   0.4406\n",
      "20\n",
      "   10   0.4611\n",
      "   20   0.4494\n",
      "   30   0.4474\n",
      "   40   0.4463\n",
      "   50   0.445\n",
      "   60   0.4441\n",
      "   70   0.4439\n",
      "   80   0.4437\n",
      "   90   0.4434\n",
      "  100   0.4432\n",
      "  110   0.4431\n",
      "  120   0.443\n",
      "  130   0.4429\n",
      "  140   0.4428\n",
      "  150   0.4425\n",
      "  160   0.4425\n",
      "  170   0.4424\n",
      "  180   0.4424\n",
      "  190   0.4425\n",
      "  200   0.4425\n",
      "25\n",
      "   10   0.4646\n",
      "   20   0.4519\n",
      "   30    0.45\n",
      "   40   0.4487\n",
      "   50   0.4472\n",
      "   60   0.4461\n",
      "   70   0.4459\n",
      "   80   0.4456\n",
      "   90   0.4451\n",
      "  100   0.4448\n",
      "  110   0.4445\n",
      "  120   0.4443\n",
      "  130   0.4443\n",
      "  140   0.444\n",
      "  150   0.4437\n",
      "  160   0.4437\n",
      "  170   0.4436\n",
      "  180   0.4437\n",
      "  190   0.4438\n",
      "  200   0.4436\n"
     ]
    }
   ],
   "source": [
    "for max_dep in [10, 15, 20, 25]:\n",
    "    print(max_dep)\n",
    "    for i in n_e:\n",
    "        f = i.astype(int)\n",
    "        clf = RandomForestRegressor(max_depth = max_dep,n_estimators=f,random_state=1,n_jobs=-1)\n",
    "        clf.fit(X_train , y_train)\n",
    "        y_pred = clf.predict(X_val)\n",
    "        rmse_ = rmse(y_val , y_pred).round(4)\n",
    "        print('%5s   %5s' % (f , rmse_))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the best `max_depth`:\n",
    "\n",
    "* 10\n",
    "* 15\n",
    "* 20\n",
    "* 25\n",
    "\n",
    "Bonus question (not graded):\n",
    "\n",
    "Will the answer be different if we change the seed for the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best max depth is 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "We can extract feature importance information from tree-based models. \n",
    "\n",
    "At each step of the decision tree learning algorith, it finds the best split. \n",
    "When doint it, we can calculate \"gain\" - the reduction in impurity before and after the split. \n",
    "This gain is quite useful in understanding what are the imporatant features \n",
    "for tree-based models.\n",
    "\n",
    "In Scikit-Learn, tree-based models contain this information in the `feature_importances_` field. \n",
    "\n",
    "For this homework question, we'll find the most important feature:\n",
    "\n",
    "* Train the model with these parametes:\n",
    "    * `n_estimators=10`,\n",
    "    * `max_depth=20`,\n",
    "    * `random_state=1`,\n",
    "    * `n_jobs=-1` (optional)\n",
    "* Get the feature importance information from this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the most important feature? \n",
    "\n",
    "* `neighbourhood_group=Manhattan`\n",
    "* `room_type=Entire home/apt`\t\n",
    "* `longitude`\n",
    "* `latitude`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train an XGBoost model! For this question, we'll tune the `eta` parameter\n",
    "\n",
    "* Install XGBoost\n",
    "* Create DMatrix for train and validation\n",
    "* Create a watchlist\n",
    "* Train a model with these parameters for 100 rounds:\n",
    "\n",
    "```\n",
    "xgb_params = {\n",
    "    'eta': 0.3, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    \n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now change `eta` first to `0.1` and then to `0.01`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which eta leads to the best RMSE score on the validation dataset?\n",
    "\n",
    "* 0.3\n",
    "* 0.1\n",
    "* 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the results\n",
    "\n",
    "\n",
    "Submit your results here: https://forms.gle/wQgFkYE6CtdDed4w8\n",
    "\n",
    "It's possible that your answers won't match exactly. If it's the case, select the closest one.\n",
    "\n",
    "\n",
    "## Deadline\n",
    "\n",
    "\n",
    "The deadline for submitting is 20 October 2021, 17:00 CET (Wednesday). After that, the form will be closed.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
